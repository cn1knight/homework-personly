# 电影推荐系统数据处理实现说明

## 系统概述

本项目是一个基于HBase的电影推荐系统，采用了多种数据处理方式来满足不同的业务需求：

- **数据导入**: 将CSV格式的电影和评分数据导入到HBase数据库
- **批处理**: 使用Apache Spark计算电影平均评分和统计信息
- **流处理**: 实时处理评分数据流，生成热门电影排行榜
- **Web界面**: 提供用户友好的查询和管理界面

## 技术架构

### 核心技术栈
- **数据库**: HBase (NoSQL分布式数据库)
- **批处理引擎**: Apache Spark
- **流处理引擎**: Spark Streaming
- **Web框架**: Flask (Python)
- **数据连接**: HappyBase (HBase Python客户端)

### 系统架构图
```
[CSV数据文件] → [数据导入模块] → [HBase数据库]
                                      ↓
[实时评分流] → [流处理模块] → [热门电影表]
                                      ↓
[批处理模块] → [评分统计表] ← [Web界面] → [用户]
```

## 1. 数据导入实现

### 1.1 数据导入概述
数据导入模块负责将CSV格式的电影数据和评分数据导入到HBase数据库中，为后续的查询和分析提供数据基础。

### 1.2 实现文件
- **主要文件**: `app.py` (数据导入相关路由)
- **数据文件**: `movies.csv`, `ratings.csv`, `ratings2.csv`

### 1.3 数据导入流程

#### 步骤1: 表结构设计
```python
# HBase表配置
MOVIES_TABLE = 'movies'           # 电影基本信息表
RATINGS_TABLE = 'ratings'         # 用户评分表
MOVIE_RATINGS_TABLE = 'movie_ratings'  # 电影评分关联表
COLUMN_FAMILY = 'info'            # 统一列族名称
```

#### 步骤2: 电影数据导入
- **数据源**: `movies.csv` (包含电影ID、标题、类型等信息)
- **处理逻辑**:
  ```python
  # 读取CSV文件
  with open('movies.csv', 'r', encoding='utf-8') as file:
      reader = csv.DictReader(file)
      
  # 批量插入HBase
  batch = table.batch(batch_size=1000)
  for row in reader:
      row_key = f"movie_{row['movieId']}"
      batch.put(row_key, {
          'info:movie_id': row['movieId'],
          'info:title': row['title'],
          'info:genres': row['genres']
      })
  ```

#### 步骤3: 评分数据导入
- **数据源**: `ratings.csv` 或 `ratings2.csv`
- **数据量**: ratings.csv (约2700万条), ratings2.csv (约10万条测试数据)
- **处理策略**: 分批处理，避免内存溢出

#### 步骤4: 进度监控
- **实现方式**: 使用全局变量和线程锁
- **功能**: 实时显示导入进度，支持Web界面查看

### 1.4 数据导入特点
- **批量处理**: 使用HBase的batch操作提高导入效率
- **进度跟踪**: 实时更新导入进度，用户可通过Web界面查看
- **错误处理**: 完善的异常处理机制，确保数据完整性
- **内存优化**: 分批读取和写入，避免大文件导致的内存问题

## 2. 批处理实现

### 2.1 批处理概述
批处理模块使用Apache Spark对历史评分数据进行离线分析，计算每部电影的平均评分、评分次数等统计信息。

### 2.2 实现文件
- **核心模块**: `movie_rating_batch.py`
- **触发器**: `trigger_batch.py`

### 2.3 批处理流程

#### 步骤1: Spark环境初始化
```python
# 创建Spark会话
spark = SparkSession.builder \
    .appName("MovieRatingBatch") \
    .config("spark.sql.shuffle.partitions", "200") \
    .config("spark.executor.memory", "4g") \
    .getOrCreate()
```

#### 步骤2: 数据读取和预处理
```python
# 读取评分数据
ratings_df = spark.read.csv(ratings_path, header=True, inferSchema=True)

# 读取电影数据
movies_df = spark.read.csv(movies_path, header=True, inferSchema=True)

# 缓存电影数据到内存
movies_df.cache()
```

#### 步骤3: 数据聚合计算
```python
# 计算每部电影的平均评分和评分次数
avg_ratings = ratings_df.groupBy("movieId") \
    .agg(
        round(avg("rating"), 2).alias("avg_rating"),
        count("rating").alias("rating_count")
    )

# 关联电影基本信息
movie_ratings = avg_ratings.join(movies_df, "movieId")
```

#### 步骤4: 结果保存到HBase
```python
# 分批保存到HBase
batch_data = []
for row in movie_ratings_list:
    batch_data.append(row)
    if len(batch_data) >= BATCH_SIZE:
        save_batch_to_hbase(batch_data)
        batch_data = []
```

### 2.4 批处理特点
- **大数据处理**: 使用Spark处理大规模评分数据
- **内存优化**: 合理配置Spark参数，优化内存使用
- **分批写入**: 避免一次性写入大量数据导致的性能问题
- **容错机制**: 完善的错误处理和重试机制

### 2.5 触发方式
1. **Web界面触发**: 通过管理页面点击"计算评分数据"按钮
2. **命令行触发**: 直接运行 `python trigger_batch.py`
3. **API触发**: 调用 `/trigger_batch` 路由

## 3. 流处理实现

### 3.1 流处理概述
流处理模块使用Spark Streaming实时处理评分数据流，计算热门电影排行榜，为用户提供实时的电影推荐。

### 3.2 实现文件
- **主要文件**: `movie_rating_stream.py`

### 3.3 流处理架构

#### 数据流架构
```
[数据生成器] → [Socket服务器] → [Spark Streaming] → [HBase]
     ↓              ↓                ↓              ↓
[模拟评分]    [TCP:9999]      [实时计算]    [热门电影表]
```

### 3.4 流处理流程

#### 步骤1: 数据源模拟
```python
def generate_ratings(movies, spark_context):
    """模拟生成实时电影评分数据"""
    while True:
        # 随机选择电影和用户
        movie_id = random.choice(movie_ids)
        user_id = random.choice(user_ids)
        rating = random.uniform(1.0, 5.0)
        
        # 构建评分数据
        rating_data = {
            "movieId": movie_id,
            "userId": user_id,
            "rating": rating,
            "timestamp": int(time.time())
        }
```

#### 步骤2: 流数据接收
```python
# 从Socket接收数据流
lines = spark.readStream \
    .format("socket") \
    .option("host", "localhost") \
    .option("port", 9999) \
    .load()
```

#### 步骤3: 实时数据处理
```python
# 解析JSON数据
ratings = lines.select(
    from_json(col("value"), rating_schema).alias("rating")
).select("rating.*")

# 添加时间戳并进行窗口聚合
ratings_with_timestamp = ratings.withColumn(
    "timestamp", 
    to_timestamp(col("timestamp").cast("timestamp"))
)

# 计算热门电影（基于评分频次）
hot_movies = ratings_with_timestamp \
    .groupBy(
        window(col("timestamp"), "1 minute"),
        col("movieId")
    ) \
    .agg(count("*").alias("rating_count")) \
    .orderBy(desc("rating_count"))
```

#### 步骤4: 结果输出到HBase
```python
def process_batch(df, epoch_id):
    """处理每个批次的数据"""
    if df.count() > 0:
        # 获取热门电影数据
        hot_movies_data = df.collect()
        
        # 保存到HBase
        timestamp = int(time.time())
        save_hot_movies_to_hbase(timestamp, json.dumps(hot_movies_data))

# 启动流处理
query = hot_movies.writeStream \
    .foreachBatch(process_batch) \
    .outputMode("complete") \
    .start()
```

### 3.5 流处理特点
- **实时性**: 秒级延迟的数据处理
- **窗口计算**: 基于时间窗口的聚合计算
- **容错性**: Spark Streaming的检查点机制
- **可扩展性**: 支持水平扩展处理能力

### 3.6 数据生成策略
- **模拟真实场景**: 基于现有电影数据生成评分
- **随机分布**: 用户ID和评分值的随机分布
- **时间戳**: 使用当前时间戳确保数据时效性

## 4. 数据存储设计

### 4.1 HBase表结构

#### 电影表 (movies)
- **Row Key**: movie_{movieId}
- **列族**: info
- **列**: movie_id, title, genres

#### 评分表 (ratings)
- **Row Key**: rating_{userId}_{movieId}_{timestamp}
- **列族**: info
- **列**: user_id, movie_id, rating, timestamp

#### 电影评分统计表 (movie_avg_ratings)
- **Row Key**: movie_{movieId}
- **列族**: info
- **列**: movie_id, title, avg_rating, rating_count, last_updated

#### 热门电影表 (hot_movies)
- **Row Key**: hot_{timestamp}
- **列族**: info
- **列**: timestamp, hot_movies (JSON格式)

### 4.2 数据访问模式
- **点查询**: 根据电影ID快速查找电影信息
- **范围扫描**: 获取热门电影列表
- **批量操作**: 大量数据的批量读写

## 5. 性能优化策略

### 5.1 HBase优化
- **合理的Row Key设计**: 避免热点问题
- **批量操作**: 使用batch提高写入效率
- **连接池**: 复用HBase连接

### 5.2 Spark优化
- **内存配置**: 合理设置executor内存
- **分区数量**: 优化shuffle分区数
- **数据缓存**: 缓存频繁访问的数据

### 5.3 应用层优化
- **异步处理**: 长时间操作使用异步执行
- **进度监控**: 实时反馈处理进度
- **错误重试**: 自动重试机制

## 6. 监控和运维

### 6.1 系统监控
- **数据库状态**: 监控HBase表的健康状态
- **处理进度**: 实时显示数据处理进度
- **错误日志**: 详细的错误信息记录

### 6.2 运维工具
- **Web管理界面**: 提供可视化的管理工具
- **命令行工具**: 支持脚本化操作
- **API接口**: 程序化的管理接口

## 7. 扩展性考虑

### 7.1 水平扩展
- **HBase集群**: 支持多节点部署
- **Spark集群**: 分布式计算能力
- **负载均衡**: Web服务的负载分担

### 7.2 功能扩展
- **推荐算法**: 集成机器学习算法
- **实时推荐**: 基于用户行为的实时推荐
- **多数据源**: 支持更多类型的数据源

## 8. 总结

本系统通过合理的架构设计和技术选型，实现了一个完整的电影推荐系统：

1. **数据导入**提供了可靠的数据基础
2. **批处理**实现了高效的离线分析
3. **流处理**支持实时的数据处理
4. **Web界面**提供了友好的用户体验

系统具有良好的可扩展性和维护性，能够满足不同规模的业务需求。通过持续的优化和改进，可以进一步提升系统的性能和功能。